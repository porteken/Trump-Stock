#train<-as_tsibble(data[1:round(nrow(data)*.95-1,0),],index=date)
#test<-as_tsibble(data[round(nrow(data)*.95-1,0):nrow(data),],index=date)
#head(data)
View(data)
data<-py$trains
invisible(getSymbols('SPY',src='yahoo',from='2018-01-10',verbose=F))
data$date<-ymd(data$date)
chartSeries(SPY)
View(data)
data<-py$trains
invisible(getSymbols('SPY',src='yahoo',from='2018-01-10',verbose=F))
data$date<-date(data$date)
chartSeries(SPY)
View(data)
prices<-fread('SPY.csv',col.names = c('date','price'))
prices$date<-mdy(prices$date)
data<-right_join(data,prices,by='date')
data<-as_tsibble(data,index=date)  %>% tsibble::fill_gaps(.full = T) %>% fill(price,.direction='down') %>% fill(score,.direction = 'down') %>% filter(score>0)
train<-as_tsibble(data[1:round(nrow(data)*.95-1,0),],index=date)
test<-as_tsibble(data[round(nrow(data)*.95-1,0):nrow(data),],index=date)
head(data)
View(data)
prices<-fread('SPY.csv',col.names = c('date','price'))
prices$date<-mdy(prices$date)
data<-right_join(data,prices,by='date')
data<-as_tsibble(data,index=date)  %>% tsibble::fill_gaps(.full = T) %>% fill(price,.direction='down') %>% fill(score,.direction = 'down') %>% filter(score>0)
data<-py$trains
invisible(getSymbols('SPY',src='yahoo',from='2018-01-10',verbose=F))
data$date<-date(data$date)
chartSeries(SPY)
prices<-fread('SPY.csv',col.names = c('date','price'))
prices$date<-mdy(prices$date)
data<-right_join(data,prices,by='date')
data<-as_tsibble(data,index=date)  %>% tsibble::fill_gaps(.full = T) %>% fill(price,.direction='down') %>% fill(score,.direction = 'down') %>% filter(score>0)
train<-as_tsibble(data[1:round(nrow(data)*.95-1,0),],index=date)
test<-as_tsibble(data[round(nrow(data)*.95-1,0):nrow(data),],index=date)
data.table(data)
fit<-train %>% model(norm=ARIMA(price~trend()),lag0=ARIMA(price~score+trend()),lag1=ARIMA(price~score+lag(score,1)+trend()),lag2=ARIMA(price~score+lag(score,1)+lag(score,2)+trend())
,lag3=ARIMA(price~score+lag(score,1)+lag(score,2)+lag(score,4)+trend()),lag4=ARIMA(price~score+lag(score,1)+lag(score,2)+lag(score,4)+lag(score,6)+trend()),nn=NNETAR(price~score))
glance(fit)
fit_best<-train %>% model(ARIMA(price~score+lag(score,1)+lag(score,2)+lag(score,4)+lag(score,6)+trend()))
report(fit_best)
gg_arma(fit_best)
fit_best %>% gg_tsresiduals()
fit_best %>% forecast(test[,1:2]) %>% autoplot(test)
fit_best %>% forecast(test[,1:2]) %>% autoplot(test)
fit_best %>% forecast(test) %>% autoplot(test)
install.packages("e1071")
install.packages("feasts")
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
install.packages("fable")
install.packages("data.table")
install.packages("data.table")
install.packages("data.table")
install.packages("data.table")
install.packages("data.table")
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY 2.csv',col.names = c('date','change'))
prices$date<-mdy(prices$date)
data<-full_join(data,prices,by='date')
data<-data %>% mutate(weekend=if_else(wday(date) %in% c(6,7),1,0),change=as.factor(change),score=lead(score,1))  %>%  fill(change,.direction='up') %>% filter(score>0) %>% select(-one_of('date','text'))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
data<-py$trains
data$date<-date(data$date)
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
future::plan('multicore')
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
library(mlr3verse)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% mutate(date=if_else(am(created_at) | wday(created_at) %in% c(7,1),date(created_at),date(created_at+days(1))),is_retweet=as.factor(if_else(is_retweet=='TRUE',1,0))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
data<-data %>% filter(text!='')
datatable(head(data))
library(tidyverse)
library(reticulate)
library(quantmod)
library(rtweet)
library(data.table)
library(lubridate)
library(e1071)
library(doParallel)
cl<-makeCluster(7)
registerDoParallel(cl)
library(DT)
library(feasts)
library(caret)
library(fable)
library(data.table)
library(tsibble)
use_condaenv('data',required=T)
data<-fread('train.csv')
data$created_at<-with_tz(parse_date_time(data$created_at,'%m/%d/%Y H:M'),tzone='US/Central')
dim(data)
data<-data %>% filter(is_retweet==F & favorite_count>0) %>% select(-one_of('is_retweet')) %>% mutate(date=if_else(am(created_at),date(created_at),date(created_at+days(1)))) %>% select(-one_of('created_at'))
dim(data)
data$text<-gsub('http\\S+\\s*','',data$text)
data$text<-gsub("[^0-9A-Za-z///' ]",'',data$text,ignore.case = T)
datatable(head(data))
data<-data %>% mutate(importance=(retweet_count+favorite_count)/2) %>% select(text,date,importance)
data<-data %>% filter(text!='') %>% group_by(date) %>% top_n(1,importance) %>% select(-one_of('importance'))
data<-py$trains
data$date<-date(data$date)
prices<-fread('SPY.csv',col.names = c('date','price'))
prices$date<-mdy(prices$date)
data<-right_join(data,prices,by='date')
data<-as_tsibble(data,index=date)  %>% tsibble::fill_gaps(.full = T) %>% fill(price,.direction='down') %>% fill(score,.direction = 'down') %>% filter(score>0)
train<-as_tsibble(data[1:round(nrow(data)*.95-1,0),],index=date)
test<-as_tsibble(data[round(nrow(data)*.95-1,0):nrow(data),],index=date)
data.table(data)
data %>% gg_tsdisplay(price,plot_type='partial')
fit<-train %>% model(norm=ARIMA(price~trend()),lag0=ARIMA(price~score+trend()),lag1=ARIMA(price~score+lag(score,1)+trend()),lag2=ARIMA(price~score+lag(score,1)+lag(score,2)+trend())
,lag3=ARIMA(price~score+lag(score,1)+lag(score,2)+lag(score,4)+trend()),lag4=ARIMA(price~score+lag(score,1)+lag(score,2)+lag(score,4)+lag(score,6)+trend()),nn=NNETAR(price~score))
glance(fit)
fit_best<-train %>% model(ARIMA(price~score+lag(score,1)+lag(score,2)+lag(score,4)+lag(score,6)+trend()))
report(fit_best)
gg_arma(fit_best)
fit_best %>% gg_tsresiduals()
fit_best %>% forecast(test) %>% autoplot(test)
